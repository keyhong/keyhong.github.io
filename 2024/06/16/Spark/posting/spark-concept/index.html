<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Spark 개념 정리, Data Engineering,Data Analysis,Python Backend">
    <meta name="description" content="Spark Cluster Mode Component

1. Driver program
애플리케이션의 main() 함수를 실행하고 SparkContext를 생성하는 프로세스


Spark의 응용 프로그램의 수명은 Dr">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Spark 개념 정리 | Keyhong</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.0.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span diy-happy-monkey">Keyhong</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <!-- <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li> -->
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Keyhong</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    

<div class="bg-cover pd-header post-cover" style="background-image: url('/images/logos/spark-logo.png')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title diy-neon-red">
                        Spark 개념 정리</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="post-cate">
                    <i class="fas fa-bookmark fa-fw icon-category"></i>
                    
                        <a href="/categories/Spark/" class="post-category">
                            Spark
                        </a>
                    
                </div>
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="Spark-Cluster-Mode-Component"><a href="#Spark-Cluster-Mode-Component" class="headerlink" title="Spark Cluster Mode Component"></a>Spark Cluster Mode Component</h2><img src="https://onedrive.live.com/embed?resid=1133AC7476AA0922%2128840&authkey=%21AAiRi8XylH3oZRI&width=596&height=286" width="596" height="286" alt="Spark Cluster Mode Component"/>

<h3 id="1-Driver-program"><a href="#1-Driver-program" class="headerlink" title="1. Driver program"></a>1. Driver program</h3><blockquote>
<p>애플리케이션의 main() 함수를 실행하고 SparkContext를 생성하는 프로세스</p>
</blockquote>
<ul>
<li><p><code>Spark의 응용 프로그램의 수명은 Driver로 시작하고 Driver로 끝난다.</code></p>
</li>
<li><p>deploy mode에 따라 클라이언트 노드 또는 클러스터에 있는 노드 중 하나에 물리적으로 상주</p>
</li>
</ul>
<h4 id="역할-1-SparkSession-생성"><a href="#역할-1-SparkSession-생성" class="headerlink" title="역할 1 : SparkSession 생성"></a>역할 1 : SparkSession 생성</h4><blockquote>
<p>스파크 모든 기능의 entry point가 되는 클래스. SparkSession 객체는 스파크 클러스터에 대한 연결을 나타냄</p>
</blockquote>
<ul>
<li>대화식 셸(spark-shell, REPL)과 스파크 응용 프로그램의 시작 부분에서 인스턴스 생성 및 프로그램 전체에 사용</li>
<li>Spark 2.0 이전에는 스파크 핵심 응용 프로그램에 사용된 <code>SparkContext</code>, <code>SQLContext</code>, <code>HiveContext</code>, <code>StreamingContext</code> 객체가 분리 되어 있었지만, <code>버전 2 이후에는 SparkSession 객체가 모든 객체를 단일 엔트리 포인트로 결합</code>해 모든 스파크 응용 프로그램에 사용 가능</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><div class="caption"><span>응용 프로그램에서 SparkSession 인스턴스 생성</span></div><code class="language-python"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql <span class="token keyword">import</span> SparkSession

spark <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder \
    <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"spark://sparkmaster:7077"</span><span class="token punctuation">)</span> \ <span class="token comment"># master 설정</span>
    <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"My Spark Application"</span><span class="token punctuation">)</span> \ <span class="token comment"># appName 설정</span>
    <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.submit.deployMode"</span><span class="token punctuation">,</span> <span class="token string">"client"</span><span class="token punctuation">)</span> \ <span class="token comment"># deploy mode 설정</span>
    <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li><p>SparkSession 객체는 자식 객체인 <code>SparkContext</code>, <code>SparkConf</code>을 통해 master, appName, Executors 등 사용자가 설정한 모든 런타임 구성 속성 포함</p>
</li>
<li><p>스파크 대화형 셸에서 SparkSession 인스턴스는 <code>spark</code>라는 이름으로 초기화됨. 비대화식 스파크 응용 프로그램(spark-submit, application)에서는 변수명을 변경 할 수 있지만, 일반적으로 spark라는 변수명을 그대로 활용</p>
</li>
</ul>
<p> <img src="https://onedrive.live.com/embed?resid=1133AC7476AA0922%2110154&authkey=%21AHL6Zgzu2Wo_IXo&width=1035&height=351" width="1035" height="351" alt="Spark Shell에서 Configuration 확인"/></p>
<h4 id="역할-2-스파크-응용-프로그램의-실행을-계획하고-조정"><a href="#역할-2-스파크-응용-프로그램의-실행을-계획하고-조정" class="headerlink" title="역할 2 : 스파크 응용 프로그램의 실행을 계획하고 조정"></a>역할 2 : 스파크 응용 프로그램의 실행을 계획하고 조정</h4><p>driver는 프로세싱 입력에 따라 프로그램을 어떻게 실행할지 계획
 </p>
<ul>
<li><p>요청된 모든 transformation 및 action에 따라 DAG를 작성. 그래프의 각 노드는 변형 또는 계산 단계를 나타냄</p>
</li>
<li><p>스파크 응용 프로그램은 작업(task)과 단계(stage)로 구성</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>용어</th>
<th>설명</th>
</tr>
</thead>
<tbody><tr>
<td>Transformation</td>
<td>데이터 조작 작업. shuffling 여부에 따라 narrow transformation과 wide transformation으로 나뉜다.</td>
</tr>
<tr>
<td>Action</td>
<td>출력 또는 프롬프트에 대한 프로그램 실행 요청</td>
</tr>
<tr>
<td>Job</td>
<td>하나의 Spark 액션 (예: save, collect)에 응답하여 생성되는 여러 작업으로 구성된 병렬 계산; 이 용어는 드라이버 로그에서 자주 볼 수 있습니다.</td>
</tr>
<tr>
<td>Task</td>
<td>하나의 executor에게 전송될 작업 단위</td>
</tr>
<tr>
<td>Stage</td>
<td>각 job은 Stage라고 불리는 서로 의존하는 작은 task 세트로 나뉘어진다(MapReduce에서의 map 및 reduce 단계와 유사). 이 용어는 driver 로그에서도 자주 볼 수 있다.</td>
</tr>
</tbody></table>
<h4 id="DAG-Directly-Acyclic-Graph"><a href="#DAG-Directly-Acyclic-Graph" class="headerlink" title="DAG (Directly Acyclic Graph)"></a>DAG (Directly Acyclic Graph)</h4><blockquote>
<p><code>방향성이 있는 비순환 그래프</code>. 데이터 흐름(data flow)와 그 종속성을 나타내기 위해 컴퓨터 과학에서 일반적으로 사용되는 수학적 구조</p>
</blockquote>
<ul>
<li><p>정점(Vertex 또는 Node), 엣지(Edge)로 구성되며, 순환참조를 가질 수 없는 방식으로 노드를 연결하기 때문에 <code>불변성(Immutability)</code>를 가짐</p>
</li>
<li><p>테즈(Tez), 드릴(Drill), 프레스토(Presto)와 같은 다른 빅데이터 에코 시스템에도 스케줄링을 위해 사용</p>
</li>
</ul>
<h4 id="응용프로그램-조직화-Orchestration"><a href="#응용프로그램-조직화-Orchestration" class="headerlink" title="응용프로그램 조직화 (Orchestration)"></a>응용프로그램 조직화 (Orchestration)</h4><p>driver는 DAG에 정의된 stage와 task의 실행을 설계함. 스케줄링 및 작업 실행과 관련된 주요 활동은 아래와 같음</p>
<ul>
<li> 실행에 사용할 수 있는 리소스 추적</li>
<li> 가능한 데이터에 ‘close’를 실행하는 작업 스케줄링<br>(<code>데이터 지역성</code> : shuffle로 발생하는 Network I&#x2F;O 비용을 줄이기 위해 데이터를 가져와 작업을 처리하는 것이 아닌, 데이터가 위치한 노드로 가서 작업을 하는 방식)</li>
</ul>
<p> </p>
<h4 id="상태-및-실행-결과를-클라이언트에게-반환"><a href="#상태-및-실행-결과를-클라이언트에게-반환" class="headerlink" title="상태 및 실행 결과를 클라이언트에게 반환"></a>상태 및 실행 결과를 클라이언트에게 반환</h4><ul>
<li> driver는 응용 프로그램의 결과를 반환하는 책임을 가짐. 데이터를 클라이언트에 반환하도록 요청되는 action의 경우 반환값은 리턴 코드 또는 데이터가 될 수 있음</li>
<li>driver는 응용 프로그램 UI를 제공. 기본 서비스 포트인 4040에 UI가 자동 생성되며, 후속 응용 프로그램이 동일한 호스트에 실행되면 4040에서 연속적인 포트 사용 (4041, 4042..)</li>
</ul>
<img src="https://onedrive.live.com/embed?resid=1133AC7476AA0922%2110153&authkey=%21AJpl3jPKEUJ7NDY&width=1034&height=445" width="1034" height="445" alt="스파크 응용 프로그램 Web UI"/>


<h3 id="2-Executor"><a href="#2-Executor" class="headerlink" title="2. Executor"></a>2. Executor</h3><blockquote>
<p>worker node에서 애플리케이션을 위해 실행되는 프로세스로, task를 실행하고 데이터를 메모리나 디스크 저장소에 유지함. 각 애플리케이션은 executor를 가지고 있음
 </p>
</blockquote>
<ul>
<li><p>Spark 애플리케이션은 많은 executor로 구성되며 병렬로 작업</p>
</li>
<li><p>일반적으로 executor를 호스팅하는 Worker Node에 유한하거나 고정된 수의 executor가 특정 시점에 할당. 따라서 노드의 수를 알고 있는 클러스터에는 주어진 시간에 실행할 수 있는 executor의 수가 한정됨</p>
</li>
<li><p>응용 프로그램이 클러스터의 실제 용량을 초과해 Executor를 요구하면, 다른 executor가 완료하고 릴리즈하는 것으로 시작되도록 예약</p>
</li>
<li><p>executor를 호스팅하는 JVM에는 객체를 저장하고 관리하는 전용 메모리 공간인 Heap이 할당. executor의 JVM 힙에 커밋된 메모리 양은 다음 두 가지로 설정 가능</p>
<ul>
<li><p>SparkSession을 생성할 때 config로 <code>spark.executor.memory</code> 설정</p>
</li>
<li><p>spakr-shell 또는 spark-submit 실행 명령 CLI에서 <code>--executor-memory</code> 아규먼트를 설정</p>
</li>
</ul>
</li>
<li><p>Worker와 Executor는 할당된 작업만 인식하지만, driver는 응용 프로그램을 구성하는 전체 작업과 관련된 종속성 파악</p>
</li>
<li><p>driver에서 생성된 Spark 응용 프로그램 UI의 <code>Executors</code> 탭에서 응용 프로그램의 executor 검사 가능</p>
</li>
</ul>
<h3 id="3-Cluster-Manager"><a href="#3-Cluster-Manager" class="headerlink" title="3. Cluster Manager"></a>3. Cluster Manager</h3><blockquote>
<p>클러스터에서 리소스를 획득하기 위한 외부 서비스 (예: standalone manager, Mesos, YARN, Kubernetes)</p>
</blockquote>
<ul>
<li><p>Mesos나 YARN에서 Spark를 실행할 때, cluster manager는 master와 분리. Standalone Mode 일 때는 Master가 Cluster Manager 역할도 함께 수행</p>
</li>
<li><p>클러스터 매니저 함수는 하둡 클러스터에서 실행되는 Spark 응용 프로그램용 YARN 리소스 매니저(RM)로 적합하다. RM은 YARN Node Manager에서 실행되는 컨테이너의 상태를 예약, 할당 및 모니터링. Spark 응용 프로그램은 cluster mode에서 실행 중인 응용 프로그램의 master(Application Master)처럼 이 컨테이너를 사용해 executor를 호스트</p>
</li>
</ul>
<h3 id="4-Master"><a href="#4-Master" class="headerlink" title="4. Master"></a>4. Master</h3><blockquote>
<p>클러스터의 리소스를 요청하고 이를 driver가 사용할 수 있게 만드는 프로세스</p>
</blockquote>
<ul>
<li><p>모든 배포 모드에서 master는 Worker Node에 리소스나 컨테이너를 할당하고, 그 상태를 추적하고 진행 상황을 모니터링함</p>
</li>
<li><p>master는 클러스터가 예약한 리소스를 executor의 형태로 제공</p>
</li>
<li><p>Spark Standalone Mode로 실행하면, master는 8080 포트에서 웹 UI를 제공함</p>
</li>
<li><p>master와 cluster manager는 독립된 프로세스로 서로 분리될 수도 있고, Spark Standalone Mode에서 Spark를 실행할 때처럼 하나의 프로세스로 결합될 수도 있음</p>
</li>
</ul>
<h4 id="Master-vs-Driver"><a href="#Master-vs-Driver" class="headerlink" title="Master vs. Driver"></a>Master vs. Driver</h4><p>driver와 master의 런타임 함수를 구별하는 것은 중요. master는 응용 프로그램의 실행을 통제하는 하는 것이 아닌, 단순히 리소스를 요청해서 Driver가 사용하게 함. <code>master는 리소스의 위치와 상태를 모니터링 하나 응용 프로그램의 실행 및 해당 작업과 단계의 조정에 관여하지 않음.</code> 이는 driver의 역할</p>
<h3 id="Worker-Node"><a href="#Worker-Node" class="headerlink" title="Worker Node"></a>Worker Node</h3><blockquote>
<p>클러스터에서 애플리케이션 코드를 실행할 수 있는 모든 노드</p>
</blockquote>
<ul>
<li>Spark Standalone Mode에서는 Worker Node는 8081 포트부터 사용자 인터페이스를 노출</li>
</ul>
<h2 id="Catalyst-Optimzer"><a href="#Catalyst-Optimzer" class="headerlink" title="Catalyst Optimzer"></a>Catalyst Optimzer</h2><ul>
<li><p>Apache Spark SQL의 핵심 컴포넌트로, 쿼리 최적화를 수행하는 역할을 수행</p>
</li>
<li><p>구조적 쿼리인 SQL 또는 DataFrame&#x2F;Dataset API의 DAG 로직을 최적화하여 프로그램 런타임과 비용을 줄여줌</p>
</li>
</ul>
<img src="https://onedrive.live.com/embed?resid=1133AC7476AA0922%2110160&authkey=%21AP8umuOWu7PFW2E&width=1033&height=240" width="1033" height="240" alt="DAG의 로직이 최적화 되는 과정"/>


<h3 id="Unresolved-Logical-Plan"><a href="#Unresolved-Logical-Plan" class="headerlink" title="Unresolved Logical Plan"></a>Unresolved Logical Plan</h3><blockquote>
<p>Column 또는 Table 이 있는 지 확인</p>
</blockquote>
<h3 id="Catalog"><a href="#Catalog" class="headerlink" title="Catalog"></a>Catalog</h3><blockquote>
<p>Spark에 있는 메타 데이터 레포지토리. 데이터 구조나 스키마 등을 가져옴</p>
</blockquote>
<h3 id="Analyzer"><a href="#Analyzer" class="headerlink" title="Analyzer"></a>Analyzer</h3><blockquote>
<p>구문, 컬럼 이름, 테이블 이름을 카탈로그와 함께 한번 더 확인 (Cross–Checking)</p>
</blockquote>
<h3 id="Resolved-Logical-Plan"><a href="#Resolved-Logical-Plan" class="headerlink" title="Resolved Logical Plan"></a>Resolved Logical Plan</h3><blockquote>
<p>카탈리스트 옵티마이저가 최적화하기 전의 상태. Logical Plan이라고도 함</p>
</blockquote>
<h3 id="Optimized-Logical-Plan"><a href="#Optimized-Logical-Plan" class="headerlink" title="Optimized Logical Plan"></a>Optimized Logical Plan</h3><blockquote>
<p>로직에 대한 퍼포먼스 평가 수행</p>
</blockquote>
<ul>
<li>Task들이 하나의 stage에서 함께 할 수 있는 지</li>
<li>여러 개의 join 쿼리를 순서를 바꾸면서 실행했을 때 퍼포먼스가 더 좋아지는 지</li>
<li>Project(join하는 컬럼들)에 filter를 먼저 적용 할 수 있는 지</li>
</ul>
<h3 id="Physical-Plan"><a href="#Physical-Plan" class="headerlink" title="Physical Plan"></a>Physical Plan</h3><blockquote>
<p>Logical Plan을 cluster가 알아들을 수 있도록 바꿈</p>
</blockquote>
<ul>
<li>여러가지의 시나리오를 생성하고 Cost Model에서 비교</li>
<li>어느 plan이 가장 빠르고 최적인지 판단 &#x3D;&gt; Selected Physical Plan</li>
</ul>
<h3 id="Codegen"><a href="#Codegen" class="headerlink" title="Codegen"></a>Codegen</h3><blockquote>
<p>Spark Tungsten Execution 엔진이 Physical Plan을 RDD로 변환</p>
</blockquote>
<h3 id="Adaptive-Planning"><a href="#Adaptive-Planning" class="headerlink" title="* Adaptive Planning"></a>* Adaptive Planning</h3><blockquote>
<p>Runtime 중 최적화 Plan을 변경한다. 예를 들어 Broadcasting Join을 하는 경우가 있다.</p>
</blockquote>
<img src="https://onedrive.live.com/embed?resid=1133AC7476AA0922%2110162&authkey=%21AHXKyDd3LIkq7gs&width=1033&height=278" width="1033" height="278" alt="Big 테이블과 Small 테이블의 Join"/>

<p>일반적으로 큰 테이블과 작은 테이블을 결합(Join)하게 되더라도 shuflle이 발생하게 된다. 문제는 작은 테이블을 결합하기 위해 큰 테이블의 모든 데이터들이 이동하게 되는 경우 이는 큰 비용이 발생한다.</p>
<p>이에 아래와 같이 작은 테이블을 모든 서버의 메모리에 올려주게 되면, shuffle 없이 각 서버는 자기의 메모리에 있는 작은 테이블을 이용해서 결합이 가능하다. spark에서 broadcast 변수를 만들어 직접 할당 할 수도 있지만 이 때는 사용자가 작은 테이블을 충분히 메모리에 올릴 수 있는 지 점검이 필요하다. 이에 반해 해당 경우는 catalyst optimzer에 의한 자동화된 최적화로 볼 수 있다.</p>
<img src="https://onedrive.live.com/embed?resid=1133AC7476AA0922%2110161&authkey=%21AH1d5ZyWkFJGJqM&width=969&height=466" width="969" height="466" alt="Broadcasting Join"/>




<h2 id="압축-지원"><a href="#압축-지원" class="headerlink" title="압축 지원"></a>압축 지원</h2><blockquote>
<p>Spark는 기본적으로 여러 가지 무손실 압축 형식을 지원</p>
</blockquote>
<ul>
<li>BZIP2로 압축된 아카이브</li>
<li>GZIP, ZIP(&#x3D;DEFLATE, 압축 방법을 사용해 생성된 모든 압축 아카이브)</li>
<li>일반적인 압축 파일 형식</li>
</ul>
<h3 id="원시-코덱-제공"><a href="#원시-코덱-제공" class="headerlink" title="원시 코덱 제공"></a>원시 코덱 제공</h3><blockquote>
<p>원시 코덱은 데이터 압축 및 압축 해제용 라이브러리</p>
</blockquote>
<ul>
<li>Built-in Codec : LZ4, LZF, LZ77 기반의 무손실 압축 형식</li>
<li>스내피 (Snappy)</li>
</ul>
<h3 id="Snappy"><a href="#Snappy" class="headerlink" title="Snappy"></a>Snappy</h3><blockquote>
<p>구글에서 자체 개발한 빠르고 분할 가능하며, CPU 자원을 덜 소모하는 데이터 압축 및 압축 해제 라이브러리</p>
</blockquote>
<ul>
<li>Hadoop의 코어 및 Hadoop-Ecosystem 프로젝트에서 일반적으로 사용</li>
<li>Worker 간에 네트워크를 통해 교환되는 RDD 데이터와 같이 Spark 내부 데이터를 압축하는 데도 사용</li>
</ul>
<h3 id="분할-가능-VS-분할-불가능"><a href="#분할-가능-VS-분할-불가능" class="headerlink" title="분할 가능 VS. 분할 불가능"></a>분할 가능 VS. 분할 불가능</h3><p>분산 처리 플랫폼(Spark, Hadoop.. )을 사용할 때, 압축 형식의 분할 가능 여부를 파악하는 것은 매우 중요</p>
<h4 id="분할-가능-압축-형식"><a href="#분할-가능-압축-형식" class="headerlink" title="분할 가능 압축 형식"></a>분할 가능 압축 형식</h4><blockquote>
<p>일반적으로 아카이브의 무결성을 손상시키지 않으면서 블록 경계에서 분할 될 수 있도록 인덱싱</p>
</blockquote>
<ul>
<li><p>Snappy나 LZO(Lempel–Ziv–Oberhumer)와 같이 분할 가능한 압축 형식은 큰 데이터 세트에 적합</p>
</li>
<li><p>따라서 HDFS와 같은 분산 파일 시스템으로 파일을 처리하기 전에 압축 해제가 좋음</p>
</li>
</ul>
<h4 id="분할-불가능한-압축-형식"><a href="#분할-불가능한-압축-형식" class="headerlink" title="분할 불가능한 압축 형식"></a>분할 불가능한 압축 형식</h4><blockquote>
<p>인덱싱 불가, 분할 불가. 분산 될 수 없기에 하나의 시스템에서 전체를 읽을 수 있어야 함</p>
</blockquote>
<ul>
<li><p>ZIP, GZIP과 같은 데스크톱 압축형식은 높은 압축률을 얻을 수 있으나 분할이 불가능</p>
</li>
<li><p>탐색 가능한 데이터가 포함된 작은 파일에는 괜찮음</p>
</li>
</ul>
<h2 id="스파크-내부-디렉터리-구조"><a href="#스파크-내부-디렉터리-구조" class="headerlink" title="스파크 내부 디렉터리 구조"></a>스파크 내부 디렉터리 구조</h2><p>스파크 내부 폴더 구조를 정리하였음. 스파크 최근 버전인 3.4.1의 내부 구조가 살짝 상이한 부분은 있으나 핵심은 바뀌지 않는 듯 하다. 글을 쓸 때 참고했던 책에는 <code>$SPARK_HOME/yarn</code> 폴더가 있었는 데 지금은 없어서 해당 폴더 설명은 지웠다. 또한 부수적인 다른 폴더들도 있으나 책에서는 중요 역할을 하는 폴더만 설명해 놓은 듯 하다. </p>
<h3 id="SPARK-HOME-bin"><a href="#SPARK-HOME-bin" class="headerlink" title="$SPARK_HOME&#x2F;bin&#x2F;"></a>$SPARK_HOME&#x2F;bin&#x2F;</h3><ul>
<li>pyspark, spark-shell, spark-sql 및 sparkR과 같은 셸 프로그램이 존재</li>
</ul>
<table>
<thead>
<tr>
<th>셸</th>
<th>설명</th>
</tr>
</thead>
<tbody><tr>
<td>spark-shell</td>
<td>대화식으로 스파크 응용 프로그램을 실행</td>
</tr>
<tr>
<td>spark-submit</td>
<td>일괄 처리 모드에서 비대화식으로 스파크 응용 프로그램을 실행</td>
</tr>
</tbody></table>
<h3 id="SPARK-HOME-conf"><a href="#SPARK-HOME-conf" class="headerlink" title="$SPARK_HOME&#x2F;conf&#x2F;"></a>$SPARK_HOME&#x2F;conf&#x2F;</h3><ul>
<li>스파크 구성 파일(<code>spark-defaults.conf.template</code>) 템플릿</li>
<li>스파크 프로세스(<code>spark-env.sh.template</code>)에 필요한 환경 변수를 설정하는 데 사용되는 쉘 스크립트</li>
<li>로깅을 제어하는 구성 템플릿(<code>log4j.properties.template</code>)이 있음</li>
<li>메트릭 컬렉션(<code>metrics.properties.template</code>)이 있음</li>
<li>워커 파일(<code>workers.template</code>) 템플릿(Standalone Mode로 실행하는 스파크 클러스터에 참여가능한 슬레이브 노드 제어)이 있다.</li>
</ul>
<h3 id="SPARK-HOME-data"><a href="#SPARK-HOME-data" class="headerlink" title="$SPARK_HOME&#x2F;data&#x2F;"></a>$SPARK_HOME&#x2F;data&#x2F;</h3><ul>
<li>스파크 프로젝트 내에서 mllib, graphx 및  streaming 라이브러리를 테스트하는 데 사용되는 Sample Data Set이다.</li>
<li>$SPARK_HOME&#x2F;examples</li>
<li>Pi 추정 응용 프로그램을 포함해 스파크 release와 함께 제공되는 모든 예제의 소스코드와 컴파일된 어셈블리(jar 파일) 폴더이다.</li>
</ul>
<h3 id="SPARK-HOME-jars"><a href="#SPARK-HOME-jars" class="headerlink" title="$SPARK_HOME&#x2F;jars&#x2F;"></a>$SPARK_HOME&#x2F;jars&#x2F;</h3><ul>
<li>스파크의 주요 어셈블리 및 snapy, py4j, parquet 등 스파크에서 사용하는 서비스를 지원하는 어셈블리 폴더이다.</li>
<li>이 디렉토리는 기본적으로 스파크의 CLASSPATH에 포함</li>
</ul>
<h3 id="SPARK-HOME-licenses"><a href="#SPARK-HOME-licenses" class="headerlink" title="$SPARK_HOME&#x2F;licenses&#x2F;"></a>$SPARK_HOME&#x2F;licenses&#x2F;</h3><ul>
<li>py4j와 jquery와 같이 따로 포함된 프로젝트를 다루는 LICENSE 파일을 포함하는 폴더이다.</li>
<li>법적 준수만을 목적으로, 스파크를 실행하는 데는 필요하지는 않는다.</li>
</ul>
<h3 id="SPARK-HOME-python"><a href="#SPARK-HOME-python" class="headerlink" title="$SPARK_HOME&#x2F;python&#x2F;"></a>$SPARK_HOME&#x2F;python&#x2F;</h3><ul>
<li>pyspark를 실행하는 데 필요한 모든 파이썬 라이브러리를 포함</li>
<li>직접적인 액세스를 할 필요는 없음</li>
<li>python에서 pip install pyspark 커맨드로도 설치가 가능한 라이브러리</li>
</ul>
<h3 id="SPARK-HOME-R"><a href="#SPARK-HOME-R" class="headerlink" title="$SPARK_HOME&#x2F;R&#x2F;"></a>$SPARK_HOME&#x2F;R&#x2F;</h3><ul>
<li>SparkR 패키지와 관련 라이브러리 및 문서를 포함</li>
</ul>
<h3 id="SPARK-HOME-sbin"><a href="#SPARK-HOME-sbin" class="headerlink" title="$SPARK_HOME&#x2F;sbin&#x2F;"></a>$SPARK_HOME&#x2F;sbin&#x2F;</h3><ul>
<li>local 또는 remote로 Spark Standalone Mode로 실행되는 스파크 클러스터의 master 및 slave 서비스를 start&#x2F;stop하고, YARN 및 Mesos와 관련된 프로세스를 시작하는 관리 스크립트를 포함하는 폴더</li>
<li>Standalone Mode에서 다중 노드 클러스터를 배포할 때 이용하는 스크립트의 일부</li>
</ul>
<h2 id="Spark-Submit"><a href="#Spark-Submit" class="headerlink" title="Spark Submit"></a>Spark Submit</h2><p>실제 클러스터에는 spark-submit을 이용하여 스파크 응용 프로그램을 실행시킴. spark-submit은 spark를 설치하면 bin 폴더($SPARK_HOME&#x2F;bin) 안에 있다. spark-submit은 컴파일된 JAR 파일을 읽어 들여 클러스터에 job을 분배 excutor가 작업을 하게 만든다. 이 모든 것을 IDE(IntelliJ, Eclipse, VSCode..) 없이 외부에서 할 수 있다. 이것이 standalone이다.<br> <br>spark-submit을 이용할 때 중요한 것은 script 내부 코드에 어떤 로컬 파일시스템 경로도 남기지 않아야 한다. 그 이유는 클러스터 노드가 어디서든 데이터 소스에 접근 가능하도록 해야 하기 때문이다. 때문에 데이터는 HDFS나 S3와 같은 공유 파일 시스템에 배포 가능하나, 클러스터 환경에서 NFS를 제외하고 특정 단일 노드의 로컬 파일시스템은 가능하지 않다.</p>
<h3 id="Submitting-Applications"><a href="#Submitting-Applications" class="headerlink" title="Submitting Applications"></a>Submitting Applications</h3><ul>
<li><p>spark-submit 실행 스크립트는 bin 디렉터리에 존재</p>
</li>
<li><p>클러스터에서 스파크 job을 제출함으로써 애플리케이션을 시작하기 위해 사용</p>
</li>
<li><p>일관성 있는 인터페이스를 통해 스파크를 지원하는 모든 클러스터 매니저를 사용가능하며, 클러스터 매니저에 대해 별도의 구성을 할 필요가 없음</p>
</li>
</ul>
<h3 id="Bundling-Your-Application’s-Dependencies"><a href="#Bundling-Your-Application’s-Dependencies" class="headerlink" title="Bundling Your Application’s Dependencies"></a>Bundling Your Application’s Dependencies</h3><p>실행 코드가 다른 라이브러리에 의존성이 있을 경우, 클러스터에 배포하기 위해 코드를 패키징하여 배포<br>패키징을 위해 Java&#x2F;Scala를 사용하는 경우 assembly jar를 만들어 배포한다. Maven&#x2F;Sbt에는 assembly-plugin이 있어 이를 이용하여 jar 파일을 만들어 낼 수 있음<br>패키징을 위해 Python을 사용하는 경우 –py-files 아규먼트를 이용해 .py | .zip | .egg 형식의 압축 파일을 함께 배포할 수 있음</p>
<h3 id="spark-submit으로-애플리케이션-시작하기"><a href="#spark-submit으로-애플리케이션-시작하기" class="headerlink" title="spark-submit으로 애플리케이션 시작하기"></a>spark-submit으로 애플리케이션 시작하기</h3><p>사용자 애플리케이션이 패키징되면 spark-submit를 이용하여 커맨드로 애플리케이션을 시작 할 수 있음. 이 때 사용 언어에 따라 classpath나 conf 등을 설정하여 여러 환경변수를 변경 가능</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 기본적인 사용에 대한 snippet</span>
$ <span class="token variable">$&#123;SPARK_HOME&#125;</span>/bin/spark-submit <span class="token punctuation">\</span>
    <span class="token parameter variable">--class</span> <span class="token operator">&lt;</span>main-class<span class="token operator">></span> <span class="token punctuation">\</span> <span class="token comment"># 자바, 스칼라로 스파크를 사용할 경우</span>
    <span class="token parameter variable">--master</span> <span class="token operator">&lt;</span>master-url<span class="token operator">></span> <span class="token punctuation">\</span>
    --deploy-mode <span class="token operator">&lt;</span>deploy-mode<span class="token operator">></span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--conf</span> <span class="token operator">&lt;</span>key<span class="token operator">>=</span><span class="token operator">&lt;</span>value<span class="token operator">></span> <span class="token punctuation">\</span>
    --py-files <span class="token punctuation">\</span> <span class="token comment"># 파이썬으로 스파크를 사용할 경우</span>
    <span class="token punctuation">..</span>. <span class="token comment"># other options</span>
    <span class="token operator">&lt;</span>application-jar<span class="token operator">></span> <span class="token punctuation">\</span> <span class="token comment"># 자바, 스칼라로 스파크를 사용할 경우</span>
    <span class="token operator">&lt;</span>application.py<span class="token operator">></span> <span class="token punctuation">\</span> <span class="token comment"># 파이썬으로 스파크를 사용할 경우</span>
    <span class="token punctuation">[</span>application-arguments<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="일반적으로-사용되는-옵션들"><a href="#일반적으로-사용되는-옵션들" class="headerlink" title="일반적으로 사용되는 옵션들"></a>일반적으로 사용되는 옵션들</h3><table>
<thead>
<tr>
<th>Option</th>
<th>Description</th>
<th>Default Value</th>
</tr>
</thead>
<tbody><tr>
<td>–class</td>
<td>애플리케이션의 Main 엔트리 포인트 (자바나 스칼라)</td>
<td></td>
</tr>
<tr>
<td>–master</td>
<td>Cluster의 Master URL. 어떤 클러스터 매니저를 사용하느냐에 따라 달라진다. <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/">https://spark.apache.org/docs/latest/</a></td>
<td>submitting-applications.html#master-urls</td>
</tr>
<tr>
<td>–deploy-mode</td>
<td>drive 프로세스를 spark job을 제출하는 client에서 실행할 것인지, cluster의 노드 중 하나에 실행 시킬 것인지 선택하는 옵션</td>
<td>client</td>
</tr>
<tr>
<td>–conf</td>
<td>&lt;key&gt;&#x3D;&lt;value&gt;로 스파크의 구성 속성을 설정하는 옵션. <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/configuration.html">https://spark.apache.org/docs/latest/configuration.html</a></td>
<td></td>
</tr>
<tr>
<td>application-jar</td>
<td>애플리케이션과 모든 종속성을 포함하는 패키징 jar의 경로. URL은 클러스터 내부에서 전역적으로 접근 가능해야 함 (자바&#x2F;스칼라)</td>
<td></td>
</tr>
<tr>
<td>–py-files</td>
<td>.py, .zip, .egg 형식의 파이썬 모듈 아카이브 (파이썬)</td>
<td></td>
</tr>
<tr>
<td>application-arguments</td>
<td>메인 클래스의 메인 메소드에 전달된 인수가 있을 때 사용</td>
<td></td>
</tr>
</tbody></table>
<h3 id="Spark-Submit-예시"><a href="#Spark-Submit-예시" class="headerlink" title="Spark Submit 예시"></a>Spark Submit 예시</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">./bin/spark-submit <span class="token punctuation">\</span>
   <span class="token parameter variable">--master</span> <span class="token function">yarn</span> <span class="token punctuation">\</span>
   --deploy-mode cluster <span class="token punctuation">\</span> <span class="token comment"># 하둡에서 클러스터 모드일 경우, driver를 임의의 노드 매니저 머신에 시작</span>
   --driver-memory 8g <span class="token punctuation">\</span> <span class="token comment"># driver 프로세스 메모리 (☆ 중요 config) </span>
   --executor-memory 16g <span class="token punctuation">\</span> <span class="token comment"># 익스큐터 프로세스 메모리 (☆ 중요 config)</span>
   --executor-cores <span class="token number">2</span>  <span class="token punctuation">\</span> <span class="token comment"># 익스큐터 코어 수. 2 이상이면 멀티 쓰레딩 (☆ 중요 config)</span>
   --py-files file1.py,file2.py,file3.zip, file4.egg <span class="token punctuation">\</span>
   wordByExample.py <span class="token punctuation">[</span>application-arguments<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<h2 id="pyspark-jvm-py4j"><a href="#pyspark-jvm-py4j" class="headerlink" title="pyspark jvm py4j"></a>pyspark jvm py4j</h2><h4 id="Question-1-PySpark-코드는-JVM-또는-Python-하위-프로세스에서-실행됩니까"><a href="#Question-1-PySpark-코드는-JVM-또는-Python-하위-프로세스에서-실행됩니까" class="headerlink" title="Question 1. PySpark 코드는 JVM 또는 Python 하위 프로세스에서 실행됩니까?"></a>Question 1. PySpark 코드는 JVM 또는 Python 하위 프로세스에서 실행됩니까?</h4><p>PySpark에서 Python 및 JVM 코드는 별도의 OS 프로세스에 있음<br>PySpark는 Python과 JVM 프로세스 간에 데이터를 교환하기 위해 두 언어 간의 상호 운용을 용이하게 하는 프레임워크인 Py4J를 사용</p>
<p>PySpark 작업을 시작하면 Python 프로세스로 시작하여 JVM 인스턴스를 생성하고 그 안에서 일부 PySpark 특정 코드를 실행한다. 그런 다음 해당 JVM에서 Spark 세션을 인스턴스화하여 Spark가 driver 프로세스가 구동 된다.<br>해당 driver는 스파크 세션이 구성된 방식에 따라 Spark 마스터에 연결하거나 in-proc 하나를 생성한다.</p>
<h2 id="데이터-지역성-Data-Locality"><a href="#데이터-지역성-Data-Locality" class="headerlink" title="데이터 지역성 (Data Locality)"></a>데이터 지역성 (Data Locality)</h2><blockquote>
<p>분산 파일 시스템에서 기본적으로 데이터와 가까운 노드에서 데이터를 읽으려는 성질. 데이터의 이동이 아닌 <code>데이터가 많은 노드에서 프로세스를 뛰워 자기의 노드에서 자기가 소유한 데이터를 읽게 하는 방식</code></p>
</blockquote>
<ul>
<li>변환 작업의 최적화에 집중하기 위해 HDFDS, S3 데이터와 같이 분산된 파티션의 데이터에 액세스한다.</li>
</ul>
<img src="https://onedrive.live.com/embed?resid=1133AC7476AA0922%219899&authkey=%21ACuYBsFlFnNgcew&width=660" width="660" height="auto" />

<ul>
<li>Spark는 다양한 저장소에 붙여서 분산 처리가 가능한 프레임워크. 처음 개발된 환경은 HDFS라는 분산 파일 시스템이며 해당 환경에서 In-Memory 기반으로 최적의 분산 처리를 수행하는 데 최적화가 되어있음. 때문에 분산 파일시스템에서 운영 할 때 데이터 지역성의 이점을 누릴 수 있다.</li>
</ul>
<h3 id="여러-Worker-Node에서-공유가능한-스토리지를-사용하지-않는-경우"><a href="#여러-Worker-Node에서-공유가능한-스토리지를-사용하지-않는-경우" class="headerlink" title="여러 Worker Node에서 공유가능한 스토리지를 사용하지 않는 경우"></a>여러 Worker Node에서 공유가능한 스토리지를 사용하지 않는 경우</h3><ul>
<li><p><code>Java.io.FileNotFoundException</code> 발생</p>
</li>
<li><p>로드 중인 파일이 클러스터의 모든 작업자 노드에서 동일한 상대 경로로 사용 가능한지 확인 필요</p>
</li>
<li><p>Spark의 RDD 파일 기반 소스로 HDFS 또는 S3 와 같은 분산 파일 시스템을 사용하는 것이 좋음</p>
</li>
<li><p>가능한 로컬 파일 시스템에서 분산 파일 시스템으로 업로드한 다음 분산된 객체에서 RDD 를 사용</p>
</li>
<li><p>또는 로컬 파일 시스템에서 사용할 경우, NFS(네트워크 파일시스템) 을 사용</p>
</li>
</ul>
<p> </p>
<h3 id="최적화의-기본"><a href="#최적화의-기본" class="headerlink" title="최적화의 기본"></a>최적화의 기본</h3><p>프로그램을 최적화 시킬 때, 두 가지 I&#x2F;O를 줄이는 것이 정말 중요하다고 생각한다. 첫 번째는 Network I&#x2F;O 이다. Network I&#x2F;O를 개선하기 위해서는 서로 다른 서버 혹은 노드 간에 통신을 하기 전 이동할 데이터의 양을 줄이고,  꼭 필요한 통신만 할 수 있도록 처리 로직을 구현하는 것이 중요하다. 그리고 두 번째는 Disk I&#x2F;O를 개선하는 것이다. Disk I&#x2F;O를 줄이는 기본은 데이터 소스에서 꼭 필요 컬럼만 추출하고 컬럼을 나타낼 수 있는 데이터 타입을 명시적으로 지정하는 일이다. 예를 들어 Python에서 int32로 표현할 수 있는 컬럼을 명시적으로 지정하지 않아 자동화된 타입 추론에 의해 Int64로 읽게 된다면 row의 한 행 마다 32 bit를 불필요하게 더 쓴다. 이는 데이터의 행이 많아질 수록 (행의 개수 * 32) bit 씩 추가적인 메모리를 소모하므로 데이터 행이 많다면 더 큰 리소스 소모를 일으킨다. 다만, 타입을 명시적으로 지정할 때 주의 할 점은 너무 최소 비트로만 데이터를 읽어 들여 범위를 넘어서는 이상 값이 발견됬을 때, 에러가 발생하거나 자동으로 더 큰 타입이으로 casting 될 수 있으므로 충분히 컬럼 값의 범위를 고려해야 한다. 내 경험 상 pandas.DataFrame에서 NaN 값이 있다면 int가 float64로 자동 캐스팅 되는 것도 볼 수 있었다. Network I&#x2F;O는 개선하는 것은 정말 어렵고 효율 개선도 한계가 있다. 때문에 Disk I&#x2F;O를 개선하는 것이 필수적이며 단순하지만 더 큰 리소스 절감을 만들 수 있다.</p>
<h3 id="Hadoop-Distributed-File-System"><a href="#Hadoop-Distributed-File-System" class="headerlink" title="Hadoop Distributed File System"></a>Hadoop Distributed File System</h3><p>HDFS(Hadoop Distributed File System)는 데이터 파일을 블록(default 128 MB) 단위로 쪼개어 클러스터의 여러 Data Node에 나눠서 저장하고 서로 복제(replication)하여 고가용성(High Availability)을 만들어 낸다. 각 블록에 대한 위치 정보는 Hadoop Cluster의 Name Node의 메모리에 저장되어 있다. Hadoop도 JVM 위에서 구동되는 하나의 프로그램이기 때문에 당연히 리소스를 관리해야 한다. Hadoop을 공부하면 블록 추상화라는 재미있는 요소가 있는 데, 한번 읽어보면 얼마나 섬세하게 설계 했는 지 그 생각을 볼 수 있다. 하여튼 Hadoop이라는 프로그램은 클러스터를 여러 노드를 제어하기 위해 일반적으로 Yarn이라는 Cluster Resource Manager를 사용한다. Hadoop Cluster에서 앱을 구동하려면 Yarn을 통해 Data Node의 리소스를 할당받고 각 노드에서 Container라는 사용 가능한 리소스의 환경을 제공받는다. 이 위에서 Spark라는 분산 처리 가능한 프로세스가 실행된다. 그렇다. 이는 우리가 Spark에서 executor라고 부르는 것이며 이것은 하나의 프로세스다. 그럼 이 프로세스는 각 Data Node에 나눠져 있는 데 어떻게 task에 데이터를 나눠줄 수 있을까?<br> <br>쉽게 생각해보자. 어떤 하나의 노드에서 데이터를 읽는다면 읽은 데이터 사이즈 만큼 메모리에 가지고 있다가 그 데이터를 파티션 개수만큼 나눠서 네트워크를 통해 다른 노드에 나눠줄 수 있지 않을 까? 가능하다. 하지만 비효율적이다. 왜냐하면 하나의 노드에서 큰 데이터를 읽는 데는 많은 시간이 걸리고, 또한 분할하는 시간과 네트워크를 통해 데이터를 전송하는 시간이 많이 걸리기 때문이다. 분명 읽어들이는 동안 다른 노드의 CPU들은 유휴 시간(idle time)을 갖게 될 것이다.<br> <br>그럼 개선할 수 있는 방법은? 당연히 나눠서 일을 하는 것이다. 각 노드들이 동시 접근한 저장소를 만들고, 각 자 읽어야 할 데이터만 읽으면 따로 나눠줄 필요도 없을 것이다. 분산 파일 시스템에서의 Spark는 이 때 빛을 발한다. 아까 HDFS에 적재된 데이터가 블록 단위로 나눠져 여러 노드에 걸쳐 분산 저장된다고 했던 말 기억하는 가? 그럼 Spark의 executor가 각각 처리할 데이터를 자신의 Data Node에서 읽어 들이면 Disk I&#x2F;O의 속도와 불필요한 Network I&#x2F;O를  줄일 수 있지 않을까?</p>
<h3 id="분산-파일-시스템을-사용하지-않는-경우"><a href="#분산-파일-시스템을-사용하지-않는-경우" class="headerlink" title="분산 파일 시스템을 사용하지 않는 경우"></a>분산 파일 시스템을 사용하지 않는 경우</h3><p>Spark를 Local Mode로 구동한다면 로컬 파일 시스템에서 데이터를 읽을 수 있겠지만,  다행히도 클러스터에서 실행되도록 구동한다면 특정 로컬 파일시스템에서 읽는 것은 불가능하게 만들어 놓았다. 만약 클러스터의 Spark 프로세스가 특정 로컬의 파일을 읽으려고 한다면 Java.io.FileNotFoundException 에러가 발생한다. 물론, 특정 노드에서 NFS(Network Files System)을 이용한다면 가능하겠지만 분산 파일 시스템에 비하면 당연히 성능이 느릴 수 밖에 없다.
 </p>
<ul>
<li>로드 중인 파일이 클러스터의 모든 작업자 노드에서 동일한 상대 경로로 사용 가능한지 확인 필요</li>
<li>스파크의 RDD 파일 기반 소스로 HDFS 또는 S3와 같은 분산 파일 시스템을 사용하는 것이 좋음</li>
<li>가능한 로컬 파일 시스템에서 분산 파일 시스템으로 업로드한 다음 분산된 객체의 RDD 를 사용</li>
<li>그럼에도 로컬 파일 시스템에서 사용하고 싶은 경우, NFS를 사용</li>
</ul>
<p> </p>
<h2 id="Caching의-필요성"><a href="#Caching의-필요성" class="headerlink" title="Caching의 필요성"></a>Caching의 필요성</h2><p>스파크는 RDD는 action을 call 하기 전까지 여러 narrow&#x2F;wide transformation로 구성된 stage를 연이어 쌓은 계보(Lineage)를 가진다. 이 Lineage는 DAG(Directed Acyclic Graph)라는 방향성은 있지만 순환하지 않는 그래프 자료 구조이다. 쉽게 비유하자면 일반통행 도로라고 생각하면 된다. 이 도로의 종착점은 action이고 지나오는 중간 지점들이 transformation이다.</p>
<img src="https://onedrive.live.com/embed?resid=1133AC7476AA0922%2110157&authkey=%21AEmB1Ph9LUNzM20&width=673&height=579" width="673" height="579" alt="transformation, stage, DAG"/>

<p>문제는 action을 call 할 때마다 Lineage의 처음부터 끝까지 다시 수행한다는 점이다. 가끔씩 스파크에서 중간 단계의 RDD를 재사용해야 하는 경우가 있다. 예를 들어, 데이터 소스에서 큰 데이터를 fetch 하는 데 많은 시간을 소요했는 데, 또 다시 이러한 고비용의 과정을 반복하는 것은 프로세싱 시간과 리소스에 있어 비효율적이다. 이를 해결하기 위한 방법은 간단하다. 중간 지점까지 수행한 RDD의 상태를 메모리나 디스크에 저장하는 것이다. 스파크에서는 이런 경우를 대비해 기존의 RDD를 재사용 할 수 있도록 <code>persist</code>와 <code>cache</code>가 함수를 지원한다.</p>
<p>원래 스파크는 in-memory 방식을 사용한다고 하는 데, 대체 왜 이런 함수를 지원하는 걸까? 스파크는 대용량의 데이터를 처리하고 다루는 데 초점이 맞춰져 있다. 당연하게도 빅데이터를 다루는 일이기에, 모든 중간 stage 과정마다 가공한 결과를 전부 메모리에 저장하고 있는 것은 당연히 불가능하다. 그렇게 한다면, OOM(Out Of Memory) 에러를 맛보고 프로세스가 중지되어 버릴 것이다. 때문에 처리하는 과정을 넘어 갈 때마다 LRU 알고리즘에 의해 오래된 데이터를 메모리에서 제거하게 된다.</p>
<p>그럼 cache도 중간 데이터를 메모리에 저장하도록 명시적으로 지시하는 것인데, cache를 위한 메모리 용량은 어떻게 설정하는 지를 봐야한다. 스파크는 Context나 Session을 만들 때 config를 수정하여 memory를 설정 할 수 있다. Spark Memory는 Storage Memory(클러스터 전체에 내부 데이터를 캐싱하고 전파)와 Execution Memory(셔플, 조인, 정렬 및 집계에서 계산에 사용)을 위한 메모리가 핵심이다. </p>
<img src="https://onedrive.live.com/embed?resid=1133AC7476AA0922%2110156&authkey=%21ALzf-xm8E1DuXsU&width=1016&height=236" width="1016" height="236" alt="Storage Level 정리표"/>

<p>RDD를 유지하면 각 노드는 메모리에서 계산하는 파티션을 저장하고 해당 데이터 세트(또는 여기에서 파생된 데이터 세트)의 다른 작업에서 재사용한다. 이를 통해 향후 작업이 훨씬 빨라질 수 있다(종종 10배 이상). 캐싱은 반복 알고리즘과 빠른 대화식 사용을 위한 핵심 도구이다.</p>
<h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><pre class="line-numbers language-python" data-language="python"><div class="caption"><span>persist()</span></div><code class="language-python"><span class="token keyword">import</span> pyspark

pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame<span class="token punctuation">.</span>persist<span class="token punctuation">(</span>
    storageLevel<span class="token punctuation">:</span> pyspark<span class="token punctuation">.</span>storagelevel<span class="token punctuation">.</span>StorageLevel <span class="token operator">=</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span> → pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>dataframe<span class="token punctuation">.</span>DataFrame

<span class="token comment"># 스파크 내에서 storageLevel을 미리 정의한 객체를 불러와 사용하는 것이 편하다.</span>
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>storagelevel <span class="token keyword">import</span> StorageLevel
DataFrame<span class="token punctuation">.</span>persist<span class="token punctuation">(</span>StorageLevel<span class="token punctuation">.</span>MEMORY_AND_DISK_DESER<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><div class="caption"><span>cache()</span></div><code class="language-python"><span class="token keyword">import</span> pyspark

pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span> → pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>dataframe<span class="token punctuation">.</span>DataFrame

<span class="token comment"># cache()는 스파크 데이터프레임의 default storage level인 persist(MEMORY_AND_DISK)를 호출하는 것과 같다.</span>
DataFrame<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/submitting-applications.html">spark.apache.org&#x2F;docs&#x2F;latest&#x2F;submitting-applications</a></li>
<li><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence">rdd-persistence</a></li>
<li><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.StorageLevel.html">pyspark.StorageLevel</a></li>
</ul>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Keyhong</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://example.com/2024/06/16/Spark/posting/spark-concept/">http://example.com/2024/06/16/Spark/posting/spark-concept/</a>
                </span>
            </div>
            <!-- <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        reprint:
                    </i>
                </span>
                <span class="reprint-info">
                    use
                    <a href="cc_by_url" rel="external nofollow noreferrer" target="_blank">cc_by_name</a>
                    licensed
                    <a href="/about" target="_blank">Keyhong</a>
                    !
                </span>
            </div> -->
        
    </div>

    <!-- <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script> -->



            <div class="tag_share" style="display: block;">
                <!-- <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            <span class="chip bg-color">No tag</span>
                        </div>
                    
                </div> -->
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <!-- <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a> -->

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    


    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2024/06/16/Trino/docker-execution/">
                    <div class="card-image">
                        
                        <img src="/images/logos/trino-logo.png" class="responsive-img" alt="Trino Quickstart">
                        
                        <span class="card-title diy-neon-red">Trino Quickstart</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-06-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Trino/" class="post-category">
                                    Trino
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2024/06/16/Python/data-structure/vecotr/">
                    <div class="card-image">
                        
                        <img src="/images/logos/data-structure-logo.jpg" class="responsive-img" alt="Vecotr">
                        
                        <span class="card-title diy-neon-red">Vecotr</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-06-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0/" class="post-category">
                                    자료구조
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;목차</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>


<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/about" target="_blank">Gyuwon Hong</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
            
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link ">
    <a href="https://github.com/keyhong" class="tooltipped" target="_blank" data-tooltip="GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:wnhong96@gmail.com" class="tooltipped" target="_blank" data-tooltip="Email" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













</div>
    </div>
</footer>

<div class="progress-bar"></div>


    
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- Back to Top Button -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
